<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <link
      href="https://fonts.googleapis.com/css?family=Lato:100,300,400,700,900"
      rel="stylesheet"
    />

    <title>Using Deep Learning to Generalize Building in Urban and Rural Areas</title>
<!--
Reflux Template
https://templatemo.com/tm-531-reflux
-->
    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet" />

    <!-- Additional CSS Files -->
    <link rel="stylesheet" href="assets/css/fontawesome.css" />
    <link rel="stylesheet" href="assets/css/templatemo-style.css" />
    <link rel="stylesheet" href="assets/css/owl.css" />
    <link rel="stylesheet" href="assets/css/lightbox.css" />
  </head>

  <body>
    <div id="page-wraper">
      <!-- Sidebar Menu -->
      <div class="responsive-nav">
        <i class="fa fa-bars" id="menu-toggle"></i>
        <div id="menu" class="menu">
          <i class="fa fa-times" id="menu-close"></i>
          <div class="container">
            <div class="author-content">
              <h4>Using Deep Learning to Generalize Building in Urban and Rural Areas</h4>
              <span>By <b>Chian-Yu, Huang </b> August 16, 2021</span>

            </div>
            <nav class="main-nav" role="navigation">
              <ul class="main-menu">
                <li><a href="#section1">Introduction</a></li>
                <li><a href="#section2">Research Question</a></li>
                <li><a href="#section3">Method</a></li>
                <li><a href="#section4">Discussion</a></li>
                <li><a href="#section5">Clonclusion</a></li>
              </ul>
            </nav>
            <div class="copyright-text">
              <p>Copyright 2019 Reflux Design</p>
            </div>
          </div>
        </div>
      </div>

      <section class="section introduction" data-section="section1">
        <div class="container">
          <div class="section-heading">
            <h2>Introduction</h2>
            <div class="line-dec"></div>
          </div>
          <div class="left-image-post">
            <div class="row">
              <h4>What is Generalization?</h4>
              <p>Generalization is the process that simplifying the complex and diverse geographic situation to a proper cartographic representation in a given map scale and purpose [<a href="https://cartographicperspectives.org/index.php/journal/article/view/cp68-roth-et-al" target="_blank">1</a>].</p>

              <h4>No Perfect Automatic Generalization Model!</h4>
              <p>The automatic generalization began with the development of geospatial information systems [<a href="http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-258f4bf9-0621-4283-b99f-97213339cfda" target="_blank">2</a>]. However, because generalization rules sometimes need to adapt to the different situations in different areas, it is impossible to use a simple parameter well build the generalization model. To solve this problem, researchers keep adapting programming frameworks trying to make model replicate the act of the cartographers’ manually generalized process [<a href="https://www.mdpi.com/2220-9964/9/8/468/htm" target="_blank">3</a>].</p>

              <h4>Problem: Building Generalization in the Urban and the Rural Areas</h4>
              <p>In the past, some research manually pre-categorized the building, some based on the building type, or the density of the building automatically separated them into several groups, and each group uses different algorithms or rules [<a href="https://www.tandfonline.com/doi/abs/10.1080/13658810410001702021" target="_blank">4</a>, <a href="https://www.tandfonline.com/doi/abs/10.1080/13658810902798099" target="_blank">5</a>, <a href="https://www.sciencedirect.com/science/article/pii/S0198971509000465" target="_blank">6</a>].  However, still some buildings were mistaken be automatically categorized then executed the wrong rules or the building on the edge of the map could not be well connected after generalized.</p>

              <h4>Potential Agent: Deep Learning</h4>
              <p>Recently, with the development of artificial intelligence and big data, deep learning has been applied in many fields, and being regarded as a great algorithm that can mimic human decision process [<a href="https://www.nature.com/articles/nature14539" target="_blank">7</a>]. Particularly in the classification and interpretation of images, the convolutional neural network (CNN) successfully detects the edge of irregular images and recognizes the different patterns [<a href="https://ieeexplore.ieee.org/abstract/document/8308186" target="_blank">8</a>], their better result confirmed that the deep learning approach better than traditional computer algorithms [<a href="https://www.sciencedirect.com/science/article/pii/S092427161630572X" target="_blank">9</a>, <a href="https://www.sciencedirect.com/science/article/pii/S0924271619300437" target="_blank">10</a>].</p>

            </div>
          </div>
        </div>
      </section>

      <section class="section research question" data-section="section2">
        <div class="container">
          <div class="section-heading">
            <h2>Research Question</h2>
            <div class="line-dec"></div>
            <span>
              <li>Is deep learning able to produce appropriate simplification for building both in urban and rural areas?</li>
              <li>Is deep learnings able to correctly generate rule-based and non-rule-based generalizations?</li>
            </span>
          </div>
          <div class="row">
            <h4>How to answer my research questions?</h4>
            <h5><b>Using End to End Training Scheme</b></h5>
            <p>End to End training means giving the model inputs and outputs data, expecting the learning algorithms can learn those unformulaic rules from the holistic data. The algorithm used in this model is deep learning, and the network architecture is the U-net structure. Input data is the ungeneralized maps and output data is the generalized maps. In order to train the model learning human cartographer generalized process, all data are manually existing maps.</p>
            <img src="assets\images\endtoend.png" alt="end to end training scheme">
            <h5><b>Building Control Group to Evaluate</b></h5>
            <p>This project built a control group to compare and evaluate deep learning results. The control group used commercial software to generate generalized output and it represents nowadays commonly used generalized results which under machine processes. The two outputs were separately compared with the fully manual generalized data, then evaluated the two compared results.</p>
          </div>
        </div>
      </section>

      <section class="section method" data-section="section3">
        <div class="container">
          <div class="section-heading">
            <h2>Method</h2>
            <div class="line-dec"></div>
            <span>In this section, details of the execution are explained in four stages: data gathering and preparation, developing U-net structure and training, generating control group, and evaluation.</span>
          </div>
          <div class="row">
            <div class="Data Gathering and Preparation">
              <h4>Data Gathering and Preparation</h4>
              <h5><b>Map Scales</b></h5>
              <p>This project executed two map scales generalization, from 1:25k to 1:50k, and from 1:50k to 100k, so there are three scales maps needed to be gathered. Table 1 shows the needed map scales for each model.</p>
              <p style="text-align: center; ">Table 1. The needed map scales for each model.</p>
              <table>
                <tr>
                  <th colspan="2">Dataset</th>
                  <th>1:25k to 1:50k</th>
                  <th>1:50k to 1:100k</th>
                </tr>
                <tr>
                  <th rowspan="2">Training Data</th>
                  <th>Input</th>
                  <td>1:25k</td>
                  <td>1:50k</td>
                </tr>
                <tr>
                  <th>Output</th>
                  <td>1:50k</td>
                  <td>1:100k</td>
                </tr>
                <tr>
                  <th colspan="2">Test Data</th>
                  <td>1:25k</td>
                  <td>1:50k</td>
                </tr>
                <tr>
                  <th colspan="2">Target Data</th>
                  <td>1:50k</td>
                  <td>1:100k</td>
                </tr>
              </table>
              <h5 style="padding: 30px 0px 0px 0px"><b>Data Sources</b></h5>
              <p>The used maps were Taiwan Mid-to-small Topographic Maps which were published in 2018 and manually generalized by human cartographers. All maps can be downloaded at <a href="https://maps.nlsc.gov.tw/MbIndex_qryPage.action?fun=8" target="_blank">the National Land Surveying and Mapping Center Taiwan MAP Service</a>. As the maps are provided in vector format, they were be rasterized in 1 m × 1 m grids image.</p>
              <h5><b>Select Areas</b></h5>
              <p>The selected area is around Taichung City, Taiwan (shown as Figure 1) that covers both urban areas and rural areas. This area was generated into a 50,893 pixel × 29,696 pixel building map and partitioned into 5,742 tiles (512pixel × 512 pixel) without overlaps. The blue block area is used in the training process, and the red block area is used for testing. Red block is adjacent and without any overlap to the blue block.</p>
              <img src="assets\images\selectarea.png" alt="Select area">
              <p style="text-align: center; line-height: 5px;">Figure 1. The select area of the model.</p>
            </div>
            <hr>
            <div class="Developing U-net Structure and Training">
              <h4>Developing U-net Structure and Training</h4>
              <h5><b>U-net Structure</b></h5>
              <p>U-net [<a href="https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28">11</a>] structure (shown as Figure 2) is a convolutional network architecture that is firstly applied in biomedical image segmentation with binary labels. It is symmetric and can be divided into an encoder-decoder path.The encoder path is the left half in the architecture diagram. Each layer consists of two repeated applications of 3 x 3 convolutions and rectified linear unit (ReLU), followed by a 2 x 2 max-pooling for downsampling. In this process, it extracts more feature channels and reduces the size of the image. The decoder path is the right half, each layer consisted of a 2 x 2 up-convolution for upsampling, followed by two 3 x 3 convolutions, which each followed by a ReLU. In this process, it reduces the feature channels and recovers the size of the image.</p>
              <img src="assets\images\unet.png" alt="U-net Structure">
              <p style="text-align: center; ">Figure 2. U-net Structure. Sources:<a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/" target="_blank">https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/</a></p>
              <p>Different from the size of the input image in the original paper, that is 572 x 572 x 3, the size of the input image used in this project is 512 x 512 x 3, and other core components of the structure kept the same. The training was used 5,445 image tiles (about 90%) as the training dataset and 297 image tiles (about 10%) as the validation dataset and scheduled for 100 epochs with batch size 32. The loss function selected binary cross-entropy and used Adam as the optimizer. In order to have a better generalization result and prevent overfitting the training data, the model applied three techniques. First, dropout was set as 0.05 to randomly drop out neural nodes during training [<a href="https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_campaign=buffer&utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com" target="_blank">12</a>, <a href="https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/" target="_blank">13</a>].
              Second, the training model automatically stopped when the value of the cost function for the cross-validation data did not improve over ten epochs [<a href="https://www.sciencedirect.com/science/article/pii/S0893608098000100" target="_blank">14</a>] Third, randomly given rotation angles, horizontal flip, and vertical flip were used in data augmentation [<a href="https://arxiv.org/abs/1712.04621" target="_blank">15</a>]. Only when the performance of the training data was the best, this model saved and used in the evaluation. </p>
              <p>Below is the code used to define the U-net model:</p>
            </div>
            <div class="code">
              <script src="https://gist.github.com/Chian-Yu/536f8b46fd2a33e42387597512ecb5bc.js"></script>
            </div>
            <hr>
            <div class="Generating Control Group">
              <h4>Generating Control Group</h4>
              <p>The commercial generalization software used in this project is ArcGIS (Version 10.8.1). ArcGIS has three generalized tools, “Delineate Built-Up Area”, "Aggregate Polygons", and “Simplify Building”.</p>
              <h5><b>Delineate Built-Up Area</b></h5>
              <p>This tool is used to merge densely clustered buildings into a large building polygon. Buildings in the input features layer are clustered together according to the giving grouping distance parameter, then merges the clustered buildings into a new building polygon. It has a better performance on merge neighbouring buildings, but in the simplifying of the edge of the building performed badly.</p>
              <img src="https://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/GUID-B21B9F22-61A8-4975-85D4-9B68C8850228-web.png" alt="Delineate Built-Up Area example">
              <p style="text-align: center">Figure 3. Delineate built-Up area example. Sources:<a href="https://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/delineate-built-up-areas.htm" target="_blank">https://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/delineate-built-up-areas.htm</a></p>
              <h5><b>Aggregate Polygons</b></h5>
              <p>The use of Aggregate Polygons is similar to Delineate Built-Up Area. By giving the aggregation distance value, the tool merges the neighbouring building that closer than the given distance together. But the orthogonality option and the function of importing barrier features, make this tool have a better performance of the simplifying edge, and avoid merging the neighbouring buildings that have barriers across.</p>
              <img src="https://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/GUID-7C771F8C-2E59-4DE5-9E46-E74A1586346D-web.gif" alt="Aggregate Polygons example">
              <p style="text-align: center">Figure 4. Aggregate polygons example. Sources:<a href="https://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/aggregate-polygons.htm" target="_blank">https://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/aggregate-polygons.htm</a></p>
              <h5><b>Simplify Building</b></h5>
              <p>This tool is used to simplify the boundary of building polygons and keep the essential shape and size of the buildings, and with the optional minimum area parameter to delete the small buildings. It has a great performance on simplification the edge of the buildings, but it did not have the function to merge the building together.</p>
              <img src="https://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/GUID-46B1682E-6993-47D0-AAED-A7D5F0F3669A-web.gif" alt="Simplify Building example">
              <p style="text-align: center">Figure 5. Simplify building example. Sources:<a href="https://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/simplify-building.htm" target="_blank">https://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/simplify-building.htm</a></p>
              <p>Each tool has its own advantages and disadvantages, but none of them can contain all the process in the building generalization. Thus, this project used two tools to produce generalized results. First using Aggregate Polygons to merge the neighbouring building, then and Simplify Building to have a better simplified edge and eliminate small buildings.</p>
            </div>
            <hr>
            <div class="Evaluation">
              <h4>Evaluation</h4>
              <p>In order to comprehensively evaluate the performance of the deep learning model, this project executed both quantitative and qualitative evaluation. </p>
              <h5><b>Quantitative Evaluation</b></h5>
              <p>The quantitative evaluation used the loss and accuracy function of the Keras. For the loss function, this project used binary cross-entropy class, it used to calculate the loss between the true labels and the prediction labels. The accuracy function used accuracy class, which is used for evaluating the performance of the model. </p>
              <h5><b>Qualitative Evaluation</b></h5>
              <p>In order to fairly evaluate the results, the test area were separated into the urban and rural areas, then both the deep learning model result and the ArcGIS tools result directly compared to the target image. The compared item are the five techniques used in building generalization process (shown as Figure 6). Each compared result was graded in five levels (very good, good, fair, poor, very poor). Then the level was used to evaluate the performance of the deep learning model and the ArcGIS tools.</p>
              <p>The process of building generalization：<br>
              It involves removing too small buildings (eliminate), adjusting the location of buildings to avoid being too close to other features (displace), replacing neighboring buildings into a larger one (merge), enlarging the small building to ensure it is legible (exaggerate), simplifying the edge of the building to make it appear less cluttered (simplify).</p>
              <img src="assets\images\process.png" alt="The process of building generalization">
              <p style="text-align: center">Figure 6. Five techniques of building generalization.</p>
              <p>Then visually examining and qualitatively describing each the compare item in urban and the rural areas in the two scales separately, illustrating the generalized situation and exploring the reason for the inappropriate generalized results.</p>
            </div>

          </div>
        </div>
      </section>

      <section class="section discussion" data-section="section4">
        <div class="container">
          <div class="section-heading">
            <h2>Discussion</h2>
            <div class="line-dec"></div>
            <span>In this section, details of the quantitative and qualitative evaluation results were be discussed first. Next, for the objective of this project discussing whether the results were expected.</span>
          </div>
          <div class="row">
            <div class="right-content">
              <div class="Quantitative evaluation">
                <h4>Quantitative Evaluation</h4>
                <p>Table 2 is the result for the deep learning model.In general, the loss and accuracy of generalization from 1:25k to 1:50k are better than generalization from 1:50k to 1:100k, the difference of the loss between them is about 5%, and the accuracy is about 2%. This showed that in the smaller scale generalization process, the variability is larger, and harder for the model to detect. Each of the models took about 30 minutes to train, and 5 minutes to predict and save the result.</p>
                <p style="text-align: center;">Table 2. Comparison of the loss and the accuracy values for each data in two model.</p>
                <table>
                  <tr>
                    <th>Scales</th>
                    <th>Dataset</th>
                    <th>Loss</th>
                    <th>Accuracy</th>
                  </tr>
                  <tr>
                    <th rowspan="3">25k</th>
                    <td>Training</td>
                    <td>0.0477</td>
                    <td>0.9848</td>
                  </tr>
                  <tr>
                    <td>Validation</td>
                    <td>0.0417</td>
                    <td>0.9867</td>
                  </tr>
                  <tr>
                    <td>Test</td>
                    <td>0.0434</td>
                    <td>0.9886</td>
                  </tr>
                  <tr>
                    <th rowspan="3">50k</th>
                    <td>Training</td>
                    <td>0.1046</td>
                    <td>0.9610</td>
                  </tr>
                  <tr>
                    <td>Validation</td>
                    <td>0.1009</td>
                    <td>0.9618</td>
                  </tr>
                  <tr>
                    <td>Test</td>
                    <td>0.1005</td>
                    <td>0.9591</td>
                  </tr>
                </table>
                <p style="padding: 10px 0px;">The accuracy and the loss for each epoch of the two models are shown in Figure 7 to 10. In general, the loss curve of both models is in a smooth descend without large noise and finally maintains a stable value, which means that both models have a good fit[<a href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/" target="_blank">15</a>]. For the accuracy curve, the generalization from 1:50k to 1:100k has a large noise during the training, which might be because the training dataset has a larger variability between the ungeneralised data and the generalized data or needed more data to train.</p>
                <img src="assets\images\25to50acc.png" alt="1:25k to 1:50k accuaacy">
                <p style="text-align: center">Figure 7. The accuracy curve of the generalization from 1:25k to 1:50k.</p>
                <img src="assets\images\25to50loss.png" alt="1:25k to 1:50k loss">
                <p style="text-align: center">Figure 8. The loss curve of the generalization from 1:25k to 1:50k.</p>
                <img src="assets\images\50to100acc.png" alt="1:50k to 1:100k accuracy">
                <p style="text-align: center">Figure 9. The accuracy curve of the generalization from 1:50k to 1:100k.</p>
                <img src="assets\images\50to100loss.png" alt="1:50k to 1:100k loss">
                <p style="text-align: center">Figure 10. The loss curve of the generalization from 1:50k to 1:100k.</p>

              </div>
              <div class="Qualitative evaluation" style="padding:40px 0px;">
                <h4>Qualitative Evaluation</h4>
                <h5><b>The generalization from 1:25k to 1:50k</b></h5>
                <p>The 1:50k generalized result’s quality comparison is shown in Table 3. In general, both the deep learning model and the ArcGIS tools performed well with the eliminating techniques, they successfully removed most small buildings; and performed worse with the exaggerating and displacing techniques, some buildings that should be exaggerated ended up being removed, and buildings that should be adjusted the displacement could not be detected. In urban areas, the deep learning model performed well than the ArcGIS tools; in rural areas, the grade of the two generalized results are similar.</p>
                <p style="text-align:center;">Table 3. Quality Comparison of 1:50k result by building generalization process.</p>
                <table>
                  <tr>
                    <th>Process</th>
                    <th>Area</th>
                    <th>Deep learning</th>
                    <th>ArcGIS</th>
                  </tr>
                  <tr>
                    <th rowspan="2">Eliminate</th>
                    <td>Urban</td>
                    <td>Very Good</td>
                    <td>Very Good</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Very Good</td>
                    <td>Very Good</td>
                  </tr>
                  <tr>
                    <th rowspan="2">Exaggerate</th>
                    <td>Urban</td>
                    <td>Poor</td>
                    <td>Very Poor</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Very Poor</td>
                    <td>Very Poor</td>
                  </tr>
                  <tr>
                    <th rowspan="2">Displace</th>
                    <td>Urban</td>
                    <td>Very Poor</td>
                    <td>Very Poor</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Unknown</td>
                    <td>Unknown</td>
                  </tr>
                  <tr>
                    <th rowspan="2">Simplify</th>
                    <td>Urban</td>
                    <td>Fair</td>
                    <td>Fair</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Fair</td>
                    <td>Fair</td>
                  </tr>
                  <tr>
                    <th rowspan="2">Merge</th>
                    <td>Urban</td>
                    <td>Good</td>
                    <td>Very Poor</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Poor</td>
                    <td>Fair</td>
                  </tr>
                </table>
                <div class="evaluate">
                  <p style="margin-top: 20px;">Figure 11 shows the results of 1:50k in urban areas, the qualitative evaluation of the figure demonstrate below, and each color represents the color of the blocks on the figure.
                    <li><b style="color:yellow;">Eliminate: </b> Both the deep learning model and the ArcGIS tools had a great performance, being able to remove the too-small buildings.</li>
                    <li><b style="color:orange;">Displace: </b> Both the deep learning model and the ArcGIS tools had a bad performance, buildings that needed to be adjusted could not be detected. For the deep learning model, the reason might be because the training data only had the building features. The displacing technique had relationships with other features, thus, without other features, the deep learning model could not learn this technique. For the ArcGIS tools, although the barrier features were imported, the displacement distance could not be set, so the model could not exactly predict the results.</li>
                    <li><b style="color:red;">Exaggerate: </b> For the deep learning model could detect some needed to be exaggerated, but the edge and the shape of the buildings performed worse, the size of the generalized building is still too small, the angle was rounded, and the edge was blurred; For the ArcGIS tools, because without this function, buildings that needed to be exaggerated preserved original areas.  </li>
                    <li><b style="color:green;">Merge: </b>The deep learning model had a better performance than the ArcGIS tools. Both the deep learning model and the ArcGIS tools missed some buildings that needed to be merged, but the ArcGIS tools wrongly merged some buildings that are unneeded to be merged. </li>
                    <li><b style="color:blue;">Simplify: </b> Because the maps might not be produced by the same person, each person’s own aesthetics could lead to different results, the shape of buildings could not totally match the target image.</li>
                  </p>
                  <img src="assets\images\fig11.png" alt="The results of 1:50k in urban areas.">
                  <p style="text-align:center;">Figure 11. The results of 1:50k in urban areas.</p>
                </div>
                <div class="evaluate">
                  <p style="margin-top: 20px;">Figure 12 shows the results of 1:50k in rural areas, in general, the results of the deep learning model and the ArcGIS tools are similar, detailed qualitative evaluation of the figure demonstrates below:
                    <li><b style="color:yellow;">Eliminate: </b> Both the deep learning model and the ArcGIS tools worked well was able to remove the too-small buildings.</li>
                    <li><b style="color:orange;">Displace: </b> Because the features were scattered and had a larger distance, in the test area, no buildings used this technique.</li>
                    <li><b style="color:red;">Exaggerate: </b> Both the deep learning model and the ArcGIS tools worked badly, most of the buildings that needed to be exaggerated could not be detected, and some of them were removed in the process.  </li>
                    <li><b style="color:green;">Merge: </b> Both the deep learning model and the ArcGIS tools had a moderate performance, being able to merge the neighbouring buildings but still some were missed or wrongly merged. </li>
                    <li><b style="color:blue;">Simplify: </b> Both the deep learning model and the ArcGIS tools had a moderate performance, being able to maintain the main shape but having a slight difference from the target image.</li>
                  </p>
                  <img src="assets\images\fig12.png" alt="The results of 1:50k in rural areas.">
                  <p style="text-align:center;">Figure 12. The results of 1:50k in rural areas.</p>
                </div>

                <h5><b>The generalization from 1:50k to 1:100k</b></h5>
                <p>The 1:100k generalized results' quality comparison is shown in Table 4. In general, both the deep learning model and the ArcGIS tools performed worse in this map scale, only the eliminating technique had a moderate performance.</p>
                <p style="text-align:center;">Table 4. Quality Comparison of 1:100k result by building generalization process.</p>
                <table>
                  <tr>
                    <th>Process</th>
                    <th>Area</th>
                    <th>Deep learning</th>
                    <th>ArcGIS</th>
                  </tr>
                  <tr>
                    <th rowspan="2">Eliminate</th>
                    <td>Urban</td>
                    <td>Fair</td>
                    <td>Fair</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Fair</td>
                    <td>Fair</td>
                  </tr>
                  <tr>
                    <th rowspan="2">Exaggerate</th>
                    <td>Urban</td>
                    <td>Unknown</td>
                    <td>Unknown</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Poor</td>
                    <td>Very Poor</td>
                  </tr>
                  <tr>
                    <th rowspan="2">Displace</th>
                    <td>Urban</td>
                    <td>Very Poor</td>
                    <td>Very Poor</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Unknown</td>
                    <td>Unknown</td>
                  </tr>
                  <tr>
                    <th rowspan="2">Simplify</th>
                    <td>Urban</td>
                    <td>Very Poor</td>
                    <td>Very Poor</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Unknown</td>
                    <td>Unknown</td>
                  </tr>
                  <tr>
                    <th rowspan="2">Merge</th>
                    <td>Urban</td>
                    <td>Very Poor</td>
                    <td>Very Poor</td>
                  </tr>
                  <tr>
                    <td>Rural</td>
                    <td>Very Poor</td>
                    <td>Poor</td>
                  </tr>
                </table>
                <div class="evaluate">
                  <p style="margin-top: 40px;">Figure 13 shows the results of 1:100k in urban areas, detailed qualitative evaluation of the figure demonstrates below:
                    <li><b style="color:yellow;">Eliminate: </b> Both the deep learning model and the ArcGIS tools had a moderate performance, they were able to remove the too-small buildings, but some of the buildings were wrongly preserved.</li>
                    <li><b style="color:orange;">Displace: </b>Both the deep learning model and the ArcGIS tools had a bad performance. The buildings that needed to adjust the displacement could not be detected, the reason is as the discussion of the 1:50k urban areas.</li>
                    <li><b style="color:red;">Exaggerate: </b> Because in this scales, most building features were dense, seldom of them used this technique. In the test area, no buildings used this technique. </li>
                    <li><b style="color:green;">Merge: </b> The deep learning model could detect which buildings needed to be merged, but the shape and the edge performed very worse. That is to say, the deep learning model was able to execute this technique but unable to predict the edge of the building, it might need to import more training data to have a better prediction. The ArcGIS tools merged the neighbouring buildings which distance was smaller than the given parameter. But without considering the content around, it missed some buildings that needed to be merged and wrongly merged some unneeded to be merged.</li>
                    <li><b style="color:blue;">Simplify: </b> For the deep learning model, the result is similar to the merging technique, being able to detect but having poor performance on the edge and the shape. For the ArcGIS tools, it simplified the edge but was still too complicated by comparing to the target data.</li>
                  </p>
                  <img src="assets\images\fig13.png" alt="The results of 1:100k in urban areas.">
                  <p style="text-align:center;">Figure 13. The results of 1:100k in urban areas.</p>
                </div>
                <div class="evaluate">
                  <p style="margin-top: 20px;">Figure 14 shows the results of 1:100k in rural areas, detailed qualitative evaluation of the figure demonstrates below:
                    <li><b style="color:yellow;">Eliminate: </b> Both the deep learning model and the ArcGIS tools had a moderate performance, they were able to remove the too-small buildings, but some of the buildings were wrongly preserved.</li>
                    <li><b style="color:orange;">Displace</b> & <b style="color:blue;">Simplify</b>: Because the features were scattered, relatively simple, and had a larger distance, no buildings used the two techniques.</li>
                    <li><b style="color:red;">Exaggerate </b>& <b style="color:green;">Merge</b>: Both the deep learning model and the ArcGIS tools in this two techniques had bad performance. For the deep learning model could detect some of the building which needed to be exaggerating or merging, but the shape and the edge of the building still had a large difference from the target image. For the ArcGIS tools could not detect which buildings needed to be exaggerating or merging. </li>
                  </p>
                  <img src="assets\images\fig14.png" alt="The results of 1:100k in rural areas.">
                  <p style="text-align:center;">Figure 14. The results of 1:100k in rural areas.</p>
                </div>

                <h4>Overall Discussion</h4>
                <h5><b>The Answer to the Research Question 1</b></h5>
                <li style="margin-top: 20px;">Is deep learning able to produce appropriate simplification for building both in urban and rural areas?
                </li>
                <p style="margin-left : 2em;">In general, the anwer is yes! The deep learning model could read the context, recognized the urban and the rural areas, according to different situations separately executed different generalized techniques then produced generalized results. But in the same size of the training dataset, the deep learning model has a better prediction on the generalization form 1:25k to 1:50k.</p>
                <p style="margin-left : 2em;">For the 1:25k to 1:50k generalized model, most too-small buildings were removed, neighbouring buildings were merged, although the displacing and exaggerating techniques still need to improve, the simplification for buildings is appropriate.</p>
                <p style="margin-left : 2em;">For the 1:50k to 1:100k generalized model, parts of the too-small buildings were removed, needed to be merged buildings could be detected, but most of the edge of the buildings are blurred, which is unacceptable for the generalized requirements. Therefore, in the smaller map scale's generalization, the model still needs to import more data to provide sufficient information.</p>
                <h5><b>The Answer to the Research Question 2</b></h5>
                <li style="margin-top: 20px;">Is deep learnings able to correctly generate rule-based and non-rule-based generalizations?</li>
                <p style="margin-left : 2em;">In general, the anwer is yes! But the rule-based generalized results is better than non-rule-based results.</p>
                <p style="margin-left : 2em;">That is because the non-rule-based generalization is more complicated and often involves the meaning that humans gave to the features. Without giving the attribute data, although the deep learning model could speculate the meaning by the context, it might still have a certain rate of error and uncertainty.</p>
                <p style="margin-left : 2em;">Such as the exaggerating technique, which is the none-rule-based generalized technique, used to preserve and exaggerate the important building. But because the meaning of importance was given by humans, and it usually needed to consider other features to define, such as road, river, or its attribute data, which caused the model to be hard to correctly predict.</p>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section class="section conclusion" data-section="section5">
        <div class="container">
          <div class="section-heading">
            <h2>Conclusion</h2>
            <div class="line-dec"></div>
          </div>
          <div class="left-image-post">
            <div class="row">
              <h4>There is a Long Way to Put into Real Utilize</h4>
              <p>In conclusion, this project aims to utilize deep learning to generalize the building in the area that both contain rural and urban.The project comfirmed that both two-scale could generate rule-based and non-rule-based results, but the rule-based result performed better than the non-rule -based results. The 1:25k to 1:50k generalization model could produce appropriate simplification, but 1:50k to 1:100k still needs to be promoted.That is to say, the deep learning generalization algorithm has the ability to deal with a complicated cartographic problem and has the potential to resolve the problems in automatic generalization in the future. But being able to put it into action still has a long way to go.</p>
              <h4>Future Works</h4>
              <h5><b>Importing More Training Data into the Deep Learning Model</b></h5>
              <p>By the evaluation result of the 1:100k outputs, it shows that the  1:50k to 1:100k generalized model is still needed to promote. It might need more data to improve the loos and the accuracy. In order to produce the acceptable outputs for this map scale I will try to use a larger size of training dataset to build and test the model again.</p>
              <h5><b>Vectorization for Output Images</b></h5>
              <p>Because this work is utilized image segmentation and recognition techniques in deep learning to realize learning human cartographer's generalized process, the inputs and outputs are in raster format. But the output data is still needed to be edited. Therefore, I will try to transform raster outputs to vector format. </p>
              <h5><b>Using Multiple Features images to Train</b></h5>
              <p>As the comparing results of displacing technique show that with only the building features images, the deep learning model was unable to predict the right generalized results. I will try using multiple features images as the training dataset to test the performance of this technique.</p>
            </div>
          </div>
        </div>
      </section>

      <section class="section Acknowledgements" data-section="section6">
        <div class="section-heading">
          <h2>Acknowledgements</h2>
          <div class="line-dec"></div>
        </div>
        My sincere thanks go to Professor Jim Thatcher for guiding this work, and Professor Luke Bergmann for programming suggestions. I also thank the 401st Plant, Materiel Production Center, Armaments Bureau, MND., R.O.C. for sponsoring my tuition to finish the whole program, and thanks to all my colleagues and supervisor for their advice and supports.
      </section>

    </div>

    <!-- Scripts -->
    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <script src="assets/js/isotope.min.js"></script>
    <script src="assets/js/owl-carousel.js"></script>
    <script src="assets/js/lightbox.js"></script>
    <script src="assets/js/custom.js"></script>
    <script>
      //according to loftblog tut
      $(".main-menu li:first").addClass("active");

      var showSection = function showSection(section, isAnimate) {
        var direction = section.replace(/#/, ""),
          reqSection = $(".section").filter(
            '[data-section="' + direction + '"]'
          ),
          reqSectionPos = reqSection.offset().top - 0;

        if (isAnimate) {
          $("body, html").animate(
            {
              scrollTop: reqSectionPos
            },
            800
          );
        } else {
          $("body, html").scrollTop(reqSectionPos);
        }
      };

      var checkSection = function checkSection() {
        $(".section").each(function() {
          var $this = $(this),
            topEdge = $this.offset().top - 80,
            bottomEdge = topEdge + $this.height(),
            wScroll = $(window).scrollTop();
          if (topEdge < wScroll && bottomEdge > wScroll) {
            var currentId = $this.data("section"),
              reqLink = $("a").filter("[href*=\\#" + currentId + "]");
            reqLink
              .closest("li")
              .addClass("active")
              .siblings()
              .removeClass("active");
          }
        });
      };

      $(".main-menu").on("click", "a", function(e) {
        e.preventDefault();
        showSection($(this).attr("href"), true);
      });

      $(window).scroll(function() {
        checkSection();
      });
    </script>
  </body>
</html>
